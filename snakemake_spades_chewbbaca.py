"""
Author: D. Merda
Affiliation: SPAAD
Aim: Benchmark : assembly with Spades and cgMLST with Chewbaca (with time)
Date: September 2024
Conda: newBacflow
Run: snakemake -s snakemake_spades_chewbbaca.py --stats time.json --cores 4 --latency-wait 60 --use-conda --conda-prefix . --conda-frontend conda
"""

# Import necessary libraries
import os
import pandas as pd

#Configuration file with YAML format that stores various workflow parameters
configfile: "config.yaml"

# Base directory where data is stored (e.g., reads files)
BASE_DIR = config['paths']['BASE_DIR']

# Working directory specific to this workflow
WDIR = config['paths']['WDIR']
# Define the working directory in Snakemake
workdir: WDIR

# Print the current working and base directories
print("The current working directory is", WDIR)
print("The base directory is", BASE_DIR)


""" 
Defining the samples to be processed
"""

# Extract sample names from the FASTQ files (compressed as .fq.gz)
SAMPLES, = glob_wildcards(config['paths']['dataset_dir']+'/{sample}_75X_GQ_1.fq.gz')

# List of prefixes corresponding to different bacterial (species) to be processed
prefixes = config['prefixes']


""" 
Defining rules in the Snakemake workflow
"""

# The main rule that specifies the final output files to be generated to complete de workflow
rule all:
    input:
        # FASTA files generated by SPAdes for each sample
        expand("{run}/assemblage_spades/{sample}_75X_spades/{sample}_75X_spades.fa", sample=SAMPLES, run=WDIR),
		# Text files containing the genome list precessed by cgMLST for each prefix
        expand("{run}/cgMLST/genome_list_{prefix}.txt", prefix=prefixes, run=WDIR),
        # Files resulting from the chewBBACA analysis (alleles.tsv, contigsInfo.tsv, statistics.tsv)
        expand(WDIR + "/cgMLST/{prefix}/alleles.tsv", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/contigsInfo.tsv", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/statistics.tsv", prefix=prefixes),
        # Distance and tree files generated by chewBBACA
        expand(WDIR + "/cgMLST/{prefix}/alleles.dist", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/alleles.tre", prefix=prefixes),

# Rule to decompress gzipped FASTQ files
rule gunzip:
    input:
        # Compressed files (paired-end reads)
        R1= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_1.fq.gz",
        R2= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_2.fq.gz"
    output:
        # Decompressed files
        R1= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_1.fq",
        R2= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_2.fq"
    shell:
        # Shell command to decompress the files
        """
        gunzip -c {input.R1} > {output.R1}
        gunzip -c {input.R2} > {output.R2}
        """

# Rule to perform de novo assembly using SPAdes
rule spades:
    input:
        # Decompressed FASTQ files
        R1= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_1.fq",
        R2= BASE_DIR + "/dataset1_spades/{sample}_75X_GQ_2.fq"
    output:
        # Contig file resulting from the assembly
        contig_spades= WDIR + "/assemblage_spades/{sample}_75X_spades/{sample}_75X_spades.fa"
    threads: 16 # Number of threads used by SPAdes
    conda: "envs/spades.yaml" # Conda environment containing SPAdes
    shell:
        """
        # Run SPAdes with the FASTQ files
        spades.py -1 {input.R1} -2 {input.R2} -o {output.contig_spades}/.. -t {threads}
        
        # Check if SPAdes completed successfuly
        if [ $? -ne 0 ]; then
            echo "SPAdes a échoué."
            exit 1
        fi
        
        # Move the output contigs to the correct location
        mv $(dirname {output.contig_spades})/contigs.fasta {output.contig_spades}
        
        # Check if the mv command was successfuly
        if [ $? -ne 0 ]; then
            echo "Le déplacement de contigs.fasta a échoué."
            exit 1
        fi
        """

# Rule to prepare the input files for chewBBACA analysis
rule chewbbaca_prepare:
    input:
        # FASTA files from SPAdes assembly
        fasta=expand(WDIR + "/assemblage_spades/{sample}_75X_spades/{sample}_75X_spades.fa", sample=SAMPLES)
    output:
        # Genome list text files for each prefix
        genome_lists=expand(WDIR + "/cgMLST/genome_list_{prefix}.txt", prefix=prefixes)
    threads: 1 # single-threaded operation
    script:
        "scripts/chewbbaca_prepare.py" # Python script to prepare input files for chewBBACA

# Rule to call alleles using chewBBACA
rule chewbbaca_allele:
    input:
        # Genome list file for a specific prefix
        genome_list=WDIR + "/cgMLST/genome_list_{prefix}.txt"
    output:
        # Output files generated by chewBBACA (alleles, contifgsInfo and statistics)
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv",
        contigsInfo=WDIR + "/cgMLST/{prefix}/contigsInfo.tsv",
        statistics=WDIR + "/cgMLST/{prefix}/statistics.tsv"
    threads: 15 # Multi-threaded operation
    params:
        # Database schema for cgMLST, defined in the config file, specific to the prefix
        schema=lambda wildcards: config['db']['cgMLST'][wildcards.prefix]
    conda: "envs/chewbbaca28.yaml" # Conda environment containing chewBBACA
    shell:
        """
        chewBBACA.py AlleleCall -i {input.genome_list} -g {params.schema} -o `dirname {output.allele}` --cpu {threads} --fr && 
        cp `dirname {output.allele}`/results_*/results_alleles.tsv `dirname {output.allele}`/alleles.tsv && 
        cp `dirname {output.allele}`/results_*/results_contigsInfo.tsv `dirname {output.allele}`/contigsInfo.tsv && 
        cp `dirname {output.allele}`/results_*/results_statistics.tsv `dirname {output.allele}`/statistics.tsv && 
        rm -r `dirname {output.allele}`/results_*
        """

# Rule to generate distance matrix with chewBBACA
rule chewbbaca_dist:
    input:
        # Alleles file generated by chewBBACA
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv"
    output:
        # Distance matrix file
        dist=WDIR + "/cgMLST/{prefix}/alleles.dist"
    threads:1 # Single-threaded operation
    conda: "envs/chewbbaca.yaml" # Conda environment for chewBBACA
    shell:
        # Run grapetree to generate the distance matrix
        "grapetree -p {input.allele} -m distance --missing 3 > {output.dist}"

# Rule to generate phylogenetic tree with chewBBACA
rule chewbbaca_tree:
    input:
        # Alleles file generated by chewBBACA
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv"
    output:
        # Tree file in Newick format
        tree=WDIR + "/cgMLST/{prefix}/alleles.tre"
    threads:1 # Single-threaded operation
    conda: "envs/chewbbaca.yaml" # Conda environment for chewBBACA
    shell:
        # Run grapetree to generate the phylogenetic tree
        "grapetree -p {input.allele} -m MSTreeV2 --missing 3 > {output.tree}"
