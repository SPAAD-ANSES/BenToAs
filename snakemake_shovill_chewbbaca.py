"""
Author: D. Merda
Affiliation: SPAAD
Aim: Benchmark : assembly with Shovill and cgMLST with Chewbaca (with time)
Date: September 2024
Conda: newBacflow
Run: snakemake -s snakemake_shovill_chewbbaca.py --stats time.json --cores 4 --latency-wait 60 --use-conda --conda-prefix . --conda-frontend conda
"""

# Import necessary libraries
import os
import pandas as pd

#Configuration file with YAML format that stores various workflow parameters
configfile: "config.yaml"

# Base directory where data is stored (e.g., reads files)
BASE_DIR = config['paths']['BASE_DIR']

# Working directory specific to this workflow
WDIR = config['paths']['WDIR']
# Define the working directory in Snakemake
workdir: WDIR

# Print the current working and base directories
print("The current working directory is", WDIR)
print("The base directory is", BASE_DIR)


""" 
Defining the samples to be processed
"""

# Extract sample names from the FASTQ files (compressed as .fq.gz)
SAMPLES, = glob_wildcards(config['paths']['dataset_dir']+'/{sample}_75X_GQ_1.fq.gz')

# List of prefixes corresponding to different bacterial (species) to be processed
prefixes = config['prefixes']


""" 
Defining rules in the Snakemake workflow
"""

# The main rule that specifies the final output files to be generated to complete de workflow
rule all:
    input:
        # FASTA files generated by Shovill for each sample
        expand("{run}/assemblage_shovill/{sample}_75X_shovill/{sample}_75X_shovill.fa", sample=SAMPLES, run=WDIR),
		# Text files containing the genome list precessed by cgMLST for each prefix
        expand("{run}/cgMLST/genome_list_{prefix}.txt", prefix=prefixes, run=WDIR),
        # Files resulting from the chewBBACA analysis (alleles.tsv, contigsInfo.tsv, statistics.tsv)
        expand(WDIR + "/cgMLST/{prefix}/alleles.tsv", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/contigsInfo.tsv", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/statistics.tsv", prefix=prefixes),
        # Distance and tree files generated by chewBBACA
        expand(WDIR + "/cgMLST/{prefix}/alleles.dist", prefix=prefixes),
        expand(WDIR + "/cgMLST/{prefix}/alleles.tre", prefix=prefixes),


# Rule to perform de novo assembly using Shovill
rule shovill:
    input:
        # Compressed FASTQ files
        R1= BASE_DIR + "/dataset1_shovill/{sample}_75X_GQ_1.fq.gz",
        R2= BASE_DIR + "/dataset1_shovill/{sample}_75X_GQ_2.fq.gz"
    output:
        # Contig file resulting from the assembly
        shovilldefault=WDIR + "/assemblage_shovilldefault/{sample}_75X_shovilldefault/{sample}_75X_shovilldefault.fa"
    conda: "envs/shovill.yaml" # Conda environment containing Unicycler
    shell:
        """
        # Run Shovill for genome assembly using paired-end reads
        shovill --outdir $(dirname {output.shovilldefault}) --R1 {input.R1} --R2 {input.R2} --force --nostitch --ram 16

        # Move the assembly output file (assembly.fasta) to the final contig output location
        mv $(dirname {output.shovilldefault})/contigs.fa {output.shovilldefault}
        """

# Rule to prepare the input files for chewBBACA analysis
rule chewbbaca_prepare:
    input:
        # FASTA files from Unicycler assembly
        fasta=expand(WDIR + "/assemblage_shovill/{sample}_75X_shovill/{sample}_75X_shovill.fa", sample=SAMPLES)
    output:
        # Genome list text files for each prefix
        genome_lists=expand(WDIR + "/cgMLST/genome_list_{prefix}.txt", prefix=prefixes)
    threads: 1 # single-threaded operation
    script:
        "scripts/chewbbaca_prepare.py" # Python script to prepare input files for chewBBACA

# Rule to call alleles using chewBBACA
rule chewbbaca_allele:
    input:
        # Genome list file for a specific prefix
        genome_list=WDIR + "/cgMLST/genome_list_{prefix}.txt"
    output:
        # Output files generated by chewBBACA (alleles, contifgsInfo and statistics)
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv",
        contigsInfo=WDIR + "/cgMLST/{prefix}/contigsInfo.tsv",
        statistics=WDIR + "/cgMLST/{prefix}/statistics.tsv"
    threads: 15 # Multi-threaded operation
    params:
        # Database schema for cgMLST, defined in the config file, specific to the prefix
        schema=lambda wildcards: config['db']['cgMLST'][wildcards.prefix]
    conda: "envs/chewbbaca28.yaml" # Conda environment containing chewBBACA
    shell:
        """
        chewBBACA.py AlleleCall -i {input.genome_list} -g {params.schema} -o `dirname {output.allele}` --cpu {threads} --fr && 
        cp `dirname {output.allele}`/results_*/results_alleles.tsv `dirname {output.allele}`/alleles.tsv && 
        cp `dirname {output.allele}`/results_*/results_contigsInfo.tsv `dirname {output.allele}`/contigsInfo.tsv && 
        cp `dirname {output.allele}`/results_*/results_statistics.tsv `dirname {output.allele}`/statistics.tsv && 
        rm -r `dirname {output.allele}`/results_*
        """

# Rule to generate distance matrix with chewBBACA
rule chewbbaca_dist:
    input:
        # Alleles file generated by chewBBACA
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv"
    output:
        # Distance matrix file
        dist=WDIR + "/cgMLST/{prefix}/alleles.dist"
    threads:1 # Single-threaded operation
    conda: "envs/chewbbaca.yaml" # Conda environment for chewBBACA
    shell:
        # Run grapetree to generate the distance matrix
        "grapetree -p {input.allele} -m distance --missing 3 > {output.dist}"

# Rule to generate phylogenetic tree with chewBBACA
rule chewbbaca_tree:
    input:
        # Alleles file generated by chewBBACA
        allele=WDIR + "/cgMLST/{prefix}/alleles.tsv"
    output:
        # Tree file in Newick format
        tree=WDIR + "/cgMLST/{prefix}/alleles.tre"
    threads:1 # Single-threaded operation
    conda: "envs/chewbbaca.yaml" # Conda environment for chewBBACA
    shell:
        # Run grapetree to generate the phylogenetic tree
        "grapetree -p {input.allele} -m MSTreeV2 --missing 3 > {output.tree}"
